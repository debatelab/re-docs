{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction of using the package `re-python`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We distinguish between two different types of RE processes:\n",
    "\n",
    "1. **Globally searching RE processes:** In each step the process optimizes the achievement function by considering **all** positions (either as theory candidates or commitments candidates).\n",
    "2. **Locally searching RE processes:** In each step the process optimizes the achievement function by considering positions that are in the neighbourhood of the current state.\n",
    "\n",
    "Accordingly, there are different RE classes to be used.\n",
    "\n",
    "Remark: \n",
    "\n",
    "+ The optimization w.r.t. a global search is computationally complex. At the moment, these processes converge in a reasonable time if the sentence pool rather small ($n< 10$). \n",
    "\n",
    "Additionally, there are two types of dialectical structures:\n",
    "\n",
    "+ *DAG (directed acyclic graphs) based dialectical structures:* All important properties of the stuctrue are calculated once and then stored. This representation is fast for smaller sentence pools and should be used in combination with globally searching RE processes.\n",
    "+ *BDD (binary decision diagramm) based dialectical structures:* Important properties of the structure are calculated by using binary decision trees. This representation is comparably fast for most properties of the graph even if the sentence pool is larger ($n>10$). However, for larger sentence it will become difficult to calculate all dialectically consistent positions, axiomatic bases (without a confining source) and minimal positions.\n",
    "\n",
    "Accordingly, we advise to use DAG based dialectical structures for globally searching RE processes and BDD based dialectical structures for locally searching RE processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Globally searching RE processes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rethon.model import StandardPosition, DAGDialecticalStructure, StandardGlobalReflectiveEquilibrium\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiating our standard example with a sentence pool $n=7$ as a DAG based dialectical structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our standard example with a sentence pool n=7\n",
    "n = 7\n",
    "arguments = [[1, 3],[1, 4],[1, 5],[1, -6], [2, -4],[2, 5],[2, 6],[2, 7]]\n",
    "dag_ds = DAGDialecticalStructure.from_arguments(arguments, n)\n",
    "global_re = StandardGlobalReflectiveEquilibrium(dag_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing a globally searching RE process with initial commitments $\\mathcal{C}_0=\\{3,4,5\\}$ and running the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_coms = StandardPosition.from_set({3, 4, 5}, n)\n",
    "global_re.set_initial_state(init_coms)\n",
    "global_re.re_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing the results. Here, `evolution` represents the sucession of RE states $C_0, T_0, C_1, T_2, \\dots , C_{final}, T_{final}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alternatives': [set(), set(), set(), set(), set(), set()],\n",
      " 'evolution': [{3, 4, 5},\n",
      "               {1},\n",
      "               {1, 3, 4, 5, -6, -2},\n",
      "               {1},\n",
      "               {1, 3, 4, 5, -6, -2},\n",
      "               {1}],\n",
      " 'finished': True}\n"
     ]
    }
   ],
   "source": [
    "pprint(global_re.state().as_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some convenience methods to show different aspects of the result: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial commitments: {3, 4, 5}\n",
      "Theory evolution: [{1}, {1}, {1}]\n",
      "Commitments evolution: [{3, 4, 5}, {1, 3, 4, 5, -6, -2}, {1, 3, 4, 5, -6, -2}]\n"
     ]
    }
   ],
   "source": [
    "print(f'Initial commitments: {global_re.state().initial_commitments()}')\n",
    "print(f'Theory evolution: {global_re.state().theory_evolution()}')\n",
    "print(f'Commitments evolution: {global_re.state().commitments_evolution()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Branching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard model searches for each step commitments or theories respectively, which optimize an achievement function of the epistemic state. If different positions compare equally well with regard to this functin, the standard model choses the next position randomly among these positions. The different possibilities for a specific model run are stored in the `alternatives` field of the RE state.\n",
    "\n",
    "However, you can also calculate all different path such a process can take given this kind of underdetermination by using a process container in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rethon.model import FullBranchREContainer\n",
    "\n",
    "init_coms = StandardPosition.from_set({3, 4, 5, 6, 7}, n)\n",
    "global_re.set_initial_state(init_coms)\n",
    "# A process container that will run all possible paths the re process can take\n",
    "re_container = FullBranchREContainer()\n",
    "branches = re_container.result_states(global_re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which will return all branches as RE states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'alternatives': [set(), {{1, 7}}, set(), set(), set(), set(), set(), set()],\n",
      "  'evolution': [{3, 4, 5, 6, 7},\n",
      "                {2, 3},\n",
      "                {2, 3, 5, 6, 7, -4, -1},\n",
      "                {2},\n",
      "                {2, 5, 6, 7, -4, -1},\n",
      "                {2},\n",
      "                {2, 5, 6, 7, -4, -1},\n",
      "                {2}],\n",
      "  'finished': True},\n",
      " {'alternatives': [set(), {{2, 3}}, set(), set(), set(), set(), set(), set()],\n",
      "  'evolution': [{3, 4, 5, 6, 7},\n",
      "                {1, 7},\n",
      "                {1, 3, 4, 5, 7, -6, -2},\n",
      "                {1},\n",
      "                {1, 3, 4, 5, -6, -2},\n",
      "                {1},\n",
      "                {1, 3, 4, 5, -6, -2},\n",
      "                {1}],\n",
      "  'finished': True}]\n"
     ]
    }
   ],
   "source": [
    "pprint([state.as_dict() for state in branches])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locally searching RE processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use locally searching RE processes, simply use `BDDDialecticalStructures` and `StandardLocalReflectiveEquilibrium` in the same way as above: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alternatives': [set(),\n",
      "                  set(),\n",
      "                  {{3, 4}, {3, 5}},\n",
      "                  set(),\n",
      "                  set(),\n",
      "                  set(),\n",
      "                  set(),\n",
      "                  set()],\n",
      " 'evolution': [{3, 4, 5}, set(), {4, 5}, {5}, {5}, {5}, {5}, {5}],\n",
      " 'finished': True}\n"
     ]
    }
   ],
   "source": [
    "from rethon.model import StandardPosition, BDDDialecticalStructure, StandardLocalReflectiveEquilibrium\n",
    "from pprint import pprint\n",
    "\n",
    "# our standard example with a sentence pool n=7\n",
    "n = 7\n",
    "arguments = [[1, 3],[1, 4],[1, 5],[1, -6], [2, -4],[2, 5],[2, 6],[2, 7]]\n",
    "bdd_ds = BDDDialecticalStructure.from_arguments(arguments, n)\n",
    "init_coms = StandardPosition.from_set({3, 4, 5}, n)\n",
    "local_re = StandardLocalReflectiveEquilibrium(bdd_ds, init_coms)\n",
    "local_re.set_initial_state(init_coms)\n",
    "local_re.re_process()\n",
    "pprint(local_re.state().as_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard model has different model parameters, which are initiated by default values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Model parameters of globally searching REs:'\n",
      "{'account_penalties': [0.0, 0.3, 1.0, 1.0],\n",
      " 'faithfulness_penalties': [0.0, 0.0, 1.0, 1.0],\n",
      " 'weights': {'account': 0.35, 'faithfulness': 0.1, 'systematicity': 0.55}}\n",
      "'Model parameters of locally searching REs:'\n",
      "{'account_penalties': [0.0, 0.3, 1.0, 1.0],\n",
      " 'faithfulness_penalties': [0.0, 0.0, 1.0, 1.0],\n",
      " 'neighbourhood_depth': 1,\n",
      " 'weights': {'account': 0.35, 'faithfulness': 0.1, 'systematicity': 0.55}}\n"
     ]
    }
   ],
   "source": [
    "pprint('Model parameters of globally searching REs:')\n",
    "pprint(global_re.model_parameters())\n",
    "pprint('Model parameters of locally searching REs:')\n",
    "pprint(local_re.model_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " and which can be set to different values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alternatives': [set(), set(), {{5}, {3}}, set(), set(), set(), set(), set()],\n",
      " 'evolution': [{3, 4, 5}, set(), {4}, {4}, {4, -2}, {4}, {4, -2}, {4}],\n",
      " 'finished': True}\n"
     ]
    }
   ],
   "source": [
    "local_re.set_model_parameters(neighbourhood_depth = 7)\n",
    "# rerunning the model\n",
    "local_re.re_process()\n",
    "pprint(local_re.state().as_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serializing RE objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can serialize\n",
    "\n",
    "* classes that implement `Position`, `DialecticalStructure`, `REState` and `ReflectiveEquilibrium`, or\n",
    "* any compounds thereof as long as the `json` python module can handle them (e.g., lists, dictionaries).\n",
    "\n",
    "For instance, the following code will serialize a position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"n_unnegated_sentence_pool\": 4,\n",
      "    \"position\": [\n",
      "        1,\n",
      "        2\n",
      "    ]\n",
      "}\n",
      "[\n",
      "    {\n",
      "        \"n_unnegated_sentence_pool\": 4,\n",
      "        \"position\": [\n",
      "            1,\n",
      "            2\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"n_unnegated_sentence_pool\": 4,\n",
      "        \"position\": [\n",
      "            1,\n",
      "            3\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"n_unnegated_sentence_pool\": 0,\n",
      "        \"position\": []\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from rethon.util import re_dumps, re_dump\n",
    "from rethon.model import StandardPosition\n",
    "from os import getcwd, path\n",
    "\n",
    "# serializing a position as JSON String\n",
    "pos_json_str = re_dumps(StandardPosition.from_set({1,2},4),\n",
    "                        indent=4)\n",
    "print(pos_json_str)\n",
    "\n",
    "# serializing a list of positions\n",
    "pos_list = [StandardPosition.from_set({1,2},4),\n",
    "            StandardPosition.from_set({1,3},4),\n",
    "            StandardPosition.from_set(set(),0)]\n",
    "print(re_dumps(pos_list, indent=4))\n",
    "\n",
    "# serializing a list of position into a file\n",
    "output_file_path = path.join(getcwd(),'positions.json')\n",
    "with open(file=output_file_path, mode='w') as output_file:\n",
    "    re_dump(pos_list, output_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If important, you can save the implementation details (module name and class name), which can be considered\n",
    "later to deserialize the objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"n_unnegated_sentence_pool\": 4,\n",
      "    \"position\": [\n",
      "        1,\n",
      "        2\n",
      "    ],\n",
      "    \"module_name\": \"rethon.numpy_implementation\",\n",
      "    \"class_name\": \"NumpyPosition\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from rethon.util import re_dumps\n",
    "from rethon.set_implementation import SetBasedPosition\n",
    "\n",
    "# serializing a position as JSON String\n",
    "pos_json_str = re_dumps(StandardPosition.from_set({1,2},4),\n",
    "                        indent=4,\n",
    "                        serialize_implementation=True)\n",
    "print(pos_json_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deserializing RE objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deserialization of RE objects is similarly simple. The implementation details can either be taken from\n",
    "the json file or can be explicitly given via parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rethon.util import re_dumps, re_loads, re_load\n",
    "from rethon.set_implementation import SetBasedPosition\n",
    "from rethon.bitarray_implementation import BitarrayPosition\n",
    "from os import getcwd, path\n",
    "\n",
    "# serializing a position as JSON String\n",
    "pos_json_str = re_dumps(SetBasedPosition.from_set({1,2},4),\n",
    "                        indent=4,\n",
    "                        serialize_implementation=True)\n",
    "# deserializing it\n",
    "position = re_loads(pos_json_str, use_json_specified_type = True )\n",
    "\n",
    "# deserializing it and using another implementation\n",
    "position = re_loads(pos_json_str,\n",
    "                    position_module = 'rethon.bitarray_implementation',\n",
    "                    position_class = 'BitarrayPosition' )\n",
    "\n",
    "# deserializing re objects from a file\n",
    "input_file_path = path.join(getcwd(),'positions.json')\n",
    "with open(file=input_file_path, mode='r') as input_file:\n",
    "    obj = re_load(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to do more than just adjust model parameters, you can alter and expand the model in different ways. The basic idea is always the same: Write an own reflective equilibrium class and overwrite methods to you own needs. \n",
    "\n",
    "An RE process is a succession of positions, starting with an initial position $\\mathcal{C_0}$:\n",
    "\n",
    "$$\n",
    "\\mathcal{C_0} \\rightarrow \\mathcal{T_0} \\rightarrow \\mathcal{C_1} \\rightarrow \\mathcal{T_1} \\rightarrow \\dots \\rightarrow \\mathcal{T_{final}} \\rightarrow \\mathcal{C_{final}}\n",
    "$$\n",
    "\n",
    "Accordingly, there are two different sorts of revisions: (i) adopting a new theory and (ii) adopting new commitments. The adoption of new theories and commitments is determined by two criteria for theories and two criteria for commitments:\n",
    "\n",
    "1. A *theory-candidates criterion* $TC$ determines theory candidates $TC_{i+1}=\\{\\mathcal{T}^{i+1}_1, \\dots \\mathcal{T}^{i+1}_n\\}$. This criterion can in principle take all past steps $\\mathcal{C_0}, \\mathcal{T_0}, \\mathcal{C_1}, \\mathcal{T_1}, \\dots, \\mathcal{T_{i}}, \\mathcal{C_{i}}$ into account. \n",
    "2. An additional criterion chooses among those candidates the next theory: $\\{\\mathcal{T}^{i+1}_1, \\dots \\mathcal{T}^{i+1}_n\\} \\rightarrow \\mathcal{T_{i+1}}$.\n",
    "3. A *commitments-candidates criterion* $CC$ determines commitments candidates $CC_{i+1}=\\{\\mathcal{C}^{i+1}_1, \\dots \\mathcal{C}^{i+1}_n\\}$. This criterion can in principle take all past steps $\\mathcal{C_0}, \\mathcal{T_0}, \\mathcal{C_1}, \\mathcal{T_1}, \\dots, \\mathcal{T_{i}}, \\mathcal{C_{i},\\mathcal{T_{i+1}} }$ into account. \n",
    "4. An additional criterion chooses among those candidates the commitment: $\\{\\mathcal{C}^{i+1}_1, \\dots \\mathcal{C}^{i+1}_n\\} \\rightarrow \\mathcal{C_{i+1}}$.\n",
    "\n",
    "\n",
    "Finally, there is a *stop criterion* that specifies under which conditions a re process is considered as finished."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extending the standard model by adjusting the achievment function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard model choses the next theory $\\mathcal{T_i}$ and the next commitments $\\mathcal{C_i}$ respectively by optimizing an achievement function \n",
    "$$\n",
    "Z(\\mathcal{C},\\mathcal{T} | \\mathcal{C}_0):= \\alpha_A A(\\mathcal{C}, \\mathcal{T})+ \\alpha_S S(\\mathcal{T}) + \\alpha_F F(\\mathcal{C}| \\mathcal{C}_0)\n",
    "$$ \n",
    "\n",
    "1. *Adopting a new theory:* Choose a theory $\\mathcal{T_{i+1}}$ that maximizes $Z(\\mathcal{C_i},\\mathcal{T_{i+1}} | \\mathcal{C}_0)$. If there are different maximizing new theories choose randomly among them, except the last theory is among them. In that case choose $\\mathcal{T_{i+1}} = \\mathcal{T_{i}}$.\n",
    "2. *Adopting new commitments:* Choose new commitments $\\mathcal{T_{i+1}}$ that maximize $Z(\\mathcal{C_{i+1}},\\mathcal{T_{i+1}} | \\mathcal{C}_0)$. If there are different maximizing new theories choose randomly among them, except the last theory is among them. In that case choose $\\mathcal{T_{i+1}} = \\mathcal{T_{i}}$.\n",
    "\n",
    "A simple way, to adapt the model is to change the functions $A$, $F$, $S$ or the achievement function as a whole.\n",
    "\n",
    "For instance, the standard model uses a quadratic term for calculating account:\n",
    "\n",
    "$$\n",
    "A(\\mathcal{C}, \\mathcal{T}):=\\left( 1-\\left(\\frac{D_{0,0.3,1,1}(\\mathcal{C}, \\overline{\\mathcal{T}})}{N}\\right)^2 \\right)\n",
    "$$\n",
    "\n",
    "If you want to get rid of the quadratic form and use instead:\n",
    "\n",
    "$$\n",
    "A(\\mathcal{C}, \\mathcal{T}):=\\left( 1-\\frac{D_{0,0.3,1,1}(\\mathcal{C}, \\overline{\\mathcal{T}})}{N} \\right)\n",
    "$$\n",
    "\n",
    "you can simply overwrite the account function of the standard model in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rethon.model import StandardPosition, DAGDialecticalStructure, StandardGlobalReflectiveEquilibrium\n",
    "\n",
    "class NewAccountReflectiveEquilibrium(StandardGlobalReflectiveEquilibrium):\n",
    "    def account(self, commitments, theory) -> float:\n",
    "        return 1 - (self.hamming_distance(commitments, \n",
    "                                          self.dialectical_structure().closure(theory),\n",
    "                                          self.model_parameter(\"account_penalties\"))\n",
    "                    /self.dialectical_structure().sentence_pool().size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And use this class as reflective equilibrium class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alternatives': [set(), set(), set(), set(), set(), set()],\n",
      " 'evolution': [{3, 4, 5},\n",
      "               {1},\n",
      "               {1, 3, 4, 5, -6, -2},\n",
      "               {1},\n",
      "               {1, 3, 4, 5, -6, -2},\n",
      "               {1}],\n",
      " 'finished': True}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# our standard example with a sentence pool n=7\n",
    "n = 7\n",
    "arguments = [[1, 3],[1, 4],[1, 5],[1, -6], [2, -4],[2, 5],[2, 6],[2, 7]]\n",
    "bdd_ds = DAGDialecticalStructure.from_arguments(arguments, n)\n",
    "new_re = NewAccountReflectiveEquilibrium(bdd_ds)\n",
    "\n",
    "init_coms = StandardPosition.from_set({3, 4, 5}, n)\n",
    "new_re.set_initial_state(init_coms)\n",
    "new_re.re_process()\n",
    "pprint(new_re.state().as_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extending the standard model by redefining the candidates criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard model uses the achievement function to determine the next commitments and theory candiates. In particular, the candidates for the next theory $\\mathcal{T}_{i+1}$ depend only on $\\mathcal{C}_{i}$ and $\\mathcal{C}_{0}$  and the candidates for the next commitments $\\mathcal{C}_{i+1}$ depend only on $\\mathcal{T}_{i+1}$ and $\\mathcal{C}_{0}$. \n",
    "\n",
    "Suppose, you want to change this behaviour. For instance, you might prefer to take other preliminary states into account. Just overwriting the achievement function (or its constituents) won't do that because you can not change which commitments and which theory will be used to calculate the achievement. However, you can overwrite the criteria that determine commitments and theory condidates directly. \n",
    "\n",
    "Suppose now, that you want to choose next commitment candidates by maximising the achievement function with respect the last commitments insteads of the initial commitments: That is, instead of maximising $Z(\\mathcal{C_{i+1}},\\mathcal{T_{i+1}} | \\mathcal{C}_0)$ you want to maximise $Z(\\mathcal{C_{i+1}},\\mathcal{T_{i+1}} | \\mathcal{C}_{i+1})$. \n",
    "\n",
    "To do that, you can simply overwrite the functions that determines the commitments candidates in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rethon.model import StandardPosition, DAGDialecticalStructure, StandardGlobalReflectiveEquilibrium\n",
    "\n",
    "class MarkovianGlobalReflectiveEquilibrium(StandardGlobalReflectiveEquilibrium):\n",
    "\n",
    "    def commitment_candidates(self, re_states = None):\n",
    "        candidate_commitments = set()\n",
    "        max_achievement = 0\n",
    "        for candidate_commitment in self.dialectical_structure().minimally_consistent_positions():\n",
    "            current_achievement = self.achievement(candidate_commitment, \n",
    "                                                   self.state().last_theory(), \n",
    "                                                   # instead of the initial commitments we calculate achievement\n",
    "                                                   # w.r.t. the last commitments\n",
    "                                                   self.state().last_commitments())\n",
    "    \n",
    "            # update achievement and candidates\n",
    "            if current_achievement > max_achievement:\n",
    "                candidate_commitments = {candidate_commitment}\n",
    "                max_achievement = current_achievement\n",
    "\n",
    "            elif current_achievement == max_achievement:\n",
    "                candidate_commitments.add(candidate_commitment)\n",
    "        # in case the last state is already optimal, we just return it\n",
    "        if self.state().last_commitments() in candidate_commitments:\n",
    "            return {self.state().last_commitments()}\n",
    "        \n",
    "        return candidate_commitments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alternatives': [set(), set(), set(), set(), set(), set()],\n",
      " 'evolution': [{3, 4, 5},\n",
      "               {1},\n",
      "               {1, 3, 4, 5, -6, -2},\n",
      "               {1},\n",
      "               {1, 3, 4, 5, -6, -2},\n",
      "               {1}],\n",
      " 'finished': True}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# our standard example with a sentence pool n=7\n",
    "n = 7\n",
    "arguments = [[1, 3],[1, 4],[1, 5],[1, -6], [2, -4],[2, 5],[2, 6],[2, 7]]\n",
    "bdd_ds = DAGDialecticalStructure.from_arguments(arguments, n)\n",
    "new_re = MarkovianGlobalReflectiveEquilibrium(bdd_ds)\n",
    "\n",
    "init_coms = StandardPosition.from_set({3, 4, 5}, n)\n",
    "new_re.set_initial_state(init_coms)\n",
    "new_re.re_process()\n",
    "pprint(new_re.state().as_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way you could adapt one of the following methods by overwriting [ReflectiveEquilibrium](https://debatelab.github.io/re-docs/api-docs/api-re.html) or classes that implement it:\n",
    "\n",
    "+ `pick_commitment_candidate`: The condition that chooses one of the commitments candidates that is determined by the commitments-candidates criterion $CC$ (`commitment_candidates`) as the next commitments.\n",
    "+ `theory_candidates` The theory-candidates criterion $CT$.\n",
    "+ `pick_theory_candidate`: The condition that chooses one of the theory candidates that is determined by the theory-candidates criterion $TC$ as the next theory.\n",
    "+ `finishedl`: The criterion that determines when the the process ends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using dirty and update to control updating of internal attribtues (To-Do) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38-kernel",
   "language": "python",
   "name": "py38-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
